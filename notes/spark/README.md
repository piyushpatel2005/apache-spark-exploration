# Apache Spark Tutorials

Apache spark is a distributed computing system that is used for big data processing and analytics. It is built on top of Hadoop and provides an easy to use API for Scala, Java, Python, and R. This repository contains a series of tutorials that cover the basics of Apache Spark.

## Table of Contents

- [Spark Overview](apache-spark-overview/index.md)
- [Spark Architecture](apache-spark-architecture/index.md)
- [Spark Development Setup](apache-spark-dev-setup/index.md)
- [Spark Shell](spark-shell/index.md)
- [Spark DataFrames](intro-to-dataframes/index.md)
- [Spark Data Sources](data-sources/index.md)
- [Spark DataFrames Operations](dataframe-operations/index.md)
- [Spark Joins](types-of-joins/index.md)
- [Spark Aggregations](aggregations/index.md)
- [Spark SQL](notes/spark-sql/index.md)
